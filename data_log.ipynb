{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Electric Energy Load Demand Forecasting for Rural Area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to read load data \n",
    "def data_reader(file_name):\n",
    "    data = pd.read_excel(file_name, parse_dates=True, index_col='Time', usecols=range(2))\n",
    "    return data\n",
    "\n",
    "# function to read weather data\n",
    "def weather_reader(file_name):\n",
    "    weather = pd.read_excel(file_name, parse_dates=True, index_col='Time measured')\n",
    "    return weather\n",
    "\n",
    "# function for concatenating load data and weather data for training\n",
    "def concat_data(file_name_load, file_name_weather):\n",
    "    train_data = pd.concat([file_name_load, file_name_weather], axis=1)\n",
    "    return train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load weather & load time-series data\n",
    "load_data = data_reader('Index_Bjønntjønn_2014_2018.xlsx')\n",
    "weather_data = weather_reader('bo_temp_2014_2018.xlsx')\n",
    "weather_data = weather_data.interpolate()\n",
    "\n",
    "# Concatenate\n",
    "dataframe = concat_data(load_data, weather_data)\n",
    "\n",
    "# Renaming columns for easier interpreting:\n",
    "dataframe = dataframe.rename(columns={\"Total\":\"Load\",\"Middeltemperatur i 2m høyde (TM)\": \"Temperature\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_plots(data, time_start, time_end=None):\n",
    "    # Ploting time-series data with different time ranges\n",
    "    fig, ax = plt.subplots(figsize=(7,4.5))\n",
    "    ax2 = ax.twinx()\n",
    "    data['Load'].loc[time_start:time_end].plot(c='seagreen', label='Load', ax=ax)\n",
    "    if time_end is None:\n",
    "        data['Temperature'].loc[time_start].plot(c='darkorange', label='Temperature', ax=ax2)\n",
    "    else:\n",
    "        data['Temperature'].loc[time_start:time_end].plot(c='darkorange', label='Temperature', ax=ax2)\n",
    "    ax.legend(loc='upper left')\n",
    "    ax2.legend(loc='upper right')\n",
    "    ax.set_ylabel('Load', fontsize=12, fontweight='bold', color='seagreen')\n",
    "    ax2.set_ylabel('Temperature', fontsize=12, fontweight='bold', color='darkorange')\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time-series for 2018\n",
    "show_plots(dataframe, '2017')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time-series for June to August 2018\n",
    "show_plots(dataframe, '2018-06', '2018-08')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_plots(dataframe, '2018-06-01', '2018-06-07')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def engineer_features(dataframe, columns, time_lags=24, drop_nan_rows=True):\n",
    "    \"\"\"Engineering features\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    dataframe: pandas dataframe\n",
    "        original dataframe with time-series data\n",
    "    columns: list\n",
    "        list of column names from the dataframe which are used for \n",
    "        feature engineering\n",
    "    time_lags: int\n",
    "        number of time lags for use with feature engineering\n",
    "    drop_nan_rows: bool\n",
    "        True/False indicator to drop rows with NaN values\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    dataframe: pandas dataframe \n",
    "        dataframe augmented with additional features \n",
    "    \"\"\"\n",
    "    \n",
    "    # Make a copy of the original dataframe\n",
    "    data = dataframe[columns].copy()\n",
    "    \n",
    "    # Hard-coding holiday dates\n",
    "    holiday_dates = {\n",
    "        # 2014 year\n",
    "        '2014-Jan-1st': ('2014-01-01', None),  # single day\n",
    "        '2014-Easter': ('2014-04-14', '2014-04-21'),  # date range\n",
    "        '2014-May-1st': ('2014-05-01', None),\n",
    "        '2014-Pentecost': ('2014-06-07', '2014-06-10'),\n",
    "        '2014-Xmas': ('2014-12-21', '2014-12-31'),\n",
    "        # 2015 year\n",
    "        '2015-Jan-1st': ('2015-01-01', None),\n",
    "        '2015-Easter': ('2015-03-30', '2015-04-06'),\n",
    "        '2015-May-1st': ('2015-05-01', None),  # Friday\n",
    "        '2015-Ascension': ('2015-05-14', None),\n",
    "        '2015-Pentecost': ('2014-05-24', '2014-05-25'),\n",
    "        '2015-Xmas': ('2015-12-23', '2015-12-31'),\n",
    "        # 2016 year\n",
    "        '2016-Jan-1st': ('2016-01-01', None),\n",
    "        '2016-Easter': ('2016-03-21', '2016-03-28'),\n",
    "        '2016-May-1st': ('2015-05-01', None),  # Sunday\n",
    "        '2016-Ascension': ('2016-05-05', None),\n",
    "        '2016-Pentecost': ('2016-05-16', '2016-05-17'),\n",
    "        '2016-Xmas': ('2016-12-26', '2016-12-31'),\n",
    "        # 2017 year\n",
    "        '2017-Jan-1st': ('2017-01-01', None),\n",
    "        '2017-Easter': ('2017-04-10', '2017-04-17'),\n",
    "        '2017-May-1st': ('2017-05-01', None),  # Monday\n",
    "        '2017-May-17th': ('2017-05-17', None),  # Wednesday\n",
    "        '2017-Ascension': ('2017-05-25', None),\n",
    "        '2017-Pentecost': ('2017-06-05', None),\n",
    "        '2017-Xmas': ('2017-12-25', '2017-12-31'),\n",
    "        # 2018 year\n",
    "        '2018-Jan-1st': ('2018-01-01', None),\n",
    "        '2018-Easter': ('2018-03-26', '2018-04-02'),\n",
    "        '2018-May-1st': ('2018-05-01', None),  # Tuesday\n",
    "        '2018-Ascension': ('2017-05-10', None),  # Thursday\n",
    "        '2018-May-17th': ('2017-05-17', None),\n",
    "        '2018-Pentecost': ('2018-05-21', None),\n",
    "        '2018-Xmas': ('2018-12-24', '2018-12-31')}\n",
    "        \n",
    "    # Features engineering\n",
    "    for col in data.columns:\n",
    "        for i in range(1, time_lags+1):\n",
    "            # Shift data by lag of 1 to time_lags (default: 24) hours\n",
    "            data[col+'_{:d}h'.format(i)] = data[col].shift(periods=i)  # time-lag\n",
    "        data[col+'_diff'] = data[col].diff()  # first-difference\n",
    "        data[col+'_week'] = data[col].shift(periods=24*7)  # previous week\n",
    "    \n",
    "    # Hour-of-day indicators with cyclical transform\n",
    "    dayhour_ind = data.index.hour\n",
    "    data['hr_sin'] = np.sin(dayhour_ind*(2.*np.pi/24))\n",
    "    data['hr_cos'] = np.cos(dayhour_ind*(2.*np.pi/24))\n",
    "    \n",
    "    # Day-of-week indicators with cyclical transform\n",
    "    weekday_ind = data.index.weekday\n",
    "    data['week_sin'] = np.sin(weekday_ind*(2.*np.pi/7))\n",
    "    data['week_cos'] = np.cos(weekday_ind*(2.*np.pi/7))\n",
    "\n",
    "    # Weekend as a binary indicator\n",
    "    data['weekend'] = np.asarray([0 if ind <= 4 else 1 for ind in weekday_ind])\n",
    "\n",
    "    # Month indicators with cyclical transform\n",
    "    month_ind = data.index.month\n",
    "    data['mnth_sin'] = np.sin((month_ind-1)*(2.*np.pi/12))\n",
    "    data['mnth_cos'] = np.cos((month_ind-1)*(2.*np.pi/12))\n",
    "    \n",
    "    # Holidays as a binary indicator\n",
    "    data['holidays'] = 0\n",
    "    for holiday, date in holiday_dates.items():\n",
    "        if date[1] is None:\n",
    "            # Single day\n",
    "            data.loc[date[0], 'holidays'] = 1\n",
    "        else:\n",
    "            # Date range\n",
    "            data.loc[date[0]:date[1], 'holidays'] = 1\n",
    "\n",
    "    if drop_nan_rows:\n",
    "        # Drop rows with NaN values\n",
    "        data.dropna(inplace=True)\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_features = engineer_features(dataframe, columns=['Load', 'Temperature'])\n",
    "data_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_features.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
